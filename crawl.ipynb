{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import urllib3\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def extract_href(src, history):\n",
    "    headers = requests.utils.default_headers()\n",
    "\n",
    "    headers.update(\n",
    "        {\n",
    "            'User-Agent': 'My User Agent 1.0',\n",
    "        }\n",
    "    )\n",
    "\n",
    "    html = requests.get(src, headers=headers).text\n",
    "\n",
    "    soup = BeautifulSoup(html, \"html.parser\")\n",
    "\n",
    "    links = soup.find_all('a')\n",
    "    href_attributes = [tag.get('href') for tag in links if tag.get('href')]\n",
    "\n",
    "    for idx, href in enumerate(href_attributes):\n",
    "        if href.startswith('http') == False:\n",
    "            href_attributes[idx] = os.path.join(src, href)\n",
    "\n",
    "    checked = []\n",
    "    for href in set(href_attributes):\n",
    "        if href in history:\n",
    "            continue\n",
    "        try:\n",
    "            resp = urllib3.request(\"GET\", href)\n",
    "            time.sleep(10)\n",
    "\n",
    "            if resp.status==200:\n",
    "                # print(f'href: {href}')\n",
    "                checked.append(href)\n",
    "        except:\n",
    "            pass\n",
    "\n",
    "    return checked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Phase 1\n",
    "valid_href = []\n",
    "\n",
    "root = 'https://www.ntu.edu.tw/'\n",
    "valid_href = extract_href(root, valid_href)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# len(set(valid_href))\n",
    "df = pd.DataFrame({'url':valid_href})\n",
    "df.to_csv('urls_1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./urls_1.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_href = df['url']\n",
    "valid_href"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm \n",
    "# Phase 2\n",
    "valid_href_2 = []\n",
    "for url in tqdm(valid_href):\n",
    "    valid_href_2.append(extract_href(url, valid_href))\n",
    "\n",
    "# for url in set(valid_href_2):\n",
    "#     if url not in valid_href:\n",
    "#         valid_href.append(url)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set([ll for l in valid_href_2 for ll in l])))\n",
    "df2 = pd.DataFrame({'url':list(set([ll for l in valid_href_2 for ll in l]))})\n",
    "df2.to_csv('urls_2.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_href_list_2 = list(set([ll for l in valid_href_2 for ll in l]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://ntubeats.ntu.edu.tw/#y2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.lib.ntu.edu.tw/node/137</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://press.ntu.edu.tw/tw/news/show.php?refe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://www.ntu.edu.tw/./campus/campus.html#ca...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.creta.org.tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2772</th>\n",
       "      <td>https://philo.ntu.edu.tw</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2773</th>\n",
       "      <td>https://ntubeats.ntu.edu.tw/enews/003/00.pdf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2774</th>\n",
       "      <td>https://ndoc.ntu.edu.tw/ifdportal_ntu/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2775</th>\n",
       "      <td>https://mis.cc.ntu.edu.tw/reg/</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2776</th>\n",
       "      <td>https://ntubeats.ntu.edu.tw/enews/95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2777 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    url\n",
       "0                    https://ntubeats.ntu.edu.tw/#y2016\n",
       "1                   https://www.lib.ntu.edu.tw/node/137\n",
       "2     https://press.ntu.edu.tw/tw/news/show.php?refe...\n",
       "3     https://www.ntu.edu.tw/./campus/campus.html#ca...\n",
       "4                              https://www.creta.org.tw\n",
       "...                                                 ...\n",
       "2772                           https://philo.ntu.edu.tw\n",
       "2773       https://ntubeats.ntu.edu.tw/enews/003/00.pdf\n",
       "2774             https://ndoc.ntu.edu.tw/ifdportal_ntu/\n",
       "2775                     https://mis.cc.ntu.edu.tw/reg/\n",
       "2776               https://ntubeats.ntu.edu.tw/enews/95\n",
       "\n",
       "[2777 rows x 1 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df2 = pd.read_csv('./urls_2.csv')\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 77/2777 [10:49:54<379:01:34, 505.37s/it]/home/ai2lab/anaconda3/envs/ngrok/lib/python3.12/site-packages/bs4/builder/__init__.py:545: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  warnings.warn(\n",
      " 15%|█▌        | 429/2777 [69:55:41<220:00:30, 337.32s/it]  "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "# Phase 3\n",
    "valid_href_3 = []\n",
    "for url in tqdm(df2['url']):\n",
    "    valid_href_3.append(extract_href(url, df2['url']))\n",
    "\n",
    "# for url in set(valid_href_3):\n",
    "#     if url not in valid_href:\n",
    "#         valid_href.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(set([ll for l in valid_href_3 for ll in l])))\n",
    "df2 = pd.DataFrame({'url':list(set([ll for l in valid_href_3 for ll in l]))})\n",
    "df2.to_csv('urls_3.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ngrok",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e36d090eb05afd206ff422f08deb8d17bebd832ca2b6ff7ff784efa083cc1f4e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
